{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93cbd1fe-f0b7-4141-b5b0-5b7d27fc9212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-09 07:47:11--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py.1’\n",
      "\n",
      "minsearch.py.1      100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-09-09 07:47:11 (14.2 MB/s) - ‘minsearch.py.1’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d6fea9-b678-467c-8383-d1b1f8154b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-06 06:20:23--  https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 658332 (643K) [text/plain]\n",
      "Saving to: ‘documents.json’\n",
      "\n",
      "documents.json      100%[===================>] 642.90K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2024-09-06 06:20:23 (65.2 MB/s) - ‘documents.json’ saved [658332/658332]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d016d5d0-5e8c-4c45-93ee-0c4b547d81c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5855f03a-efcb-4c38-bd1a-6b77ec6160cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06d1407d-f454-4e2d-ad01-2b60454c5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e6505c8-ec61-4201-96a7-5713dae690cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93e07fad-3287-4a44-8347-bd77a5126480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - Can I still join the course after the start date?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6459f831-ff47-46c6-a536-8b3e48018832",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields = [\"question\",\"text\",\"section\"],\n",
    "    keyword_fields = [\"course\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57b08339-1976-4985-bafc-0aa17cb8d42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7074a849e3f0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "599b8327-35b5-4f31-9f13-3d7276b64c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f989745f-384f-4a9e-a2eb-128d312d1dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Reload the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify the new API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dd53a35c-fa34-4f99-8177-de79bde9bfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.44.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (2.9.0)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.2)\n",
      "Requirement already satisfied: tzdata in /home/codespace/.local/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2024.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8f4779b1-0815-4e39-b7c0-b7029aa4d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d26bc7a5-8415-4cc9-b9ce-000f536fcf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get openai client\n",
    "oppenai_client = OpenAI(api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "60394af6-9c17-4449-8f25-c83eb1c8976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section':0.5}\n",
    "    \n",
    "    results = index.search(\n",
    "        query = query,\n",
    "        filter_dict = {'course' : 'data-engineering-zoomcamp'},\n",
    "        boost_dict = boost,\n",
    "        num_results = 5\n",
    "    )\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3a12fe37-de58-428f-be6c-af8424c0bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    propmt_template = \"\"\"\n",
    "    You are a course teaching assistant. Anser the QUESTION based on the CONTEXT from the FAQ database. \n",
    "    Use only the facts from the context when answering the questions. \n",
    "    \n",
    "    QUESTION : {question}\n",
    "    \n",
    "    CONTEXT : {context}\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section : {doc['section']}\\nquestion: {doc['question']}\\nanswer : {doc['text']}\\n\\n\"\n",
    "\n",
    "    prompt = propmt_template.format(question = query, context = context).strip()\n",
    "\n",
    "    return prompt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "09deed8f-aa49-4fa3-838f-d93703b7cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_response(prompt):\n",
    "    response = oppenai_client.chat.completions.create(\n",
    "    model = \"gpt-4o\",\n",
    "    messages = [{\"role\":\"user\", \"content\": prompt}]\n",
    ")\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "221c982c-959d-4150-bde8-13d532eefc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    results = search(query)\n",
    "    prompt = build_prompt(query, results)\n",
    "    response = llm_response(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3444d808-f644-4032-9883-f01c0d5ed517",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"The course has already started. can I still enroll?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c7eec546-6fd2-47e4-bf82-af2098fd6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8681bbf9-2ab2-4235-8b0c-d84dff9d1fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can still enroll and join the course even after it has started. You're also eligible to submit the homework assignments. However, please be mindful of the deadlines for the final projects to avoid last-minute submissions.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b183788-ca6b-4e89-86c6-e0bcb81155ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch\n",
      "  Downloading elasticsearch-8.15.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting elastic-transport<9,>=8.13 (from elasticsearch)\n",
      "  Downloading elastic_transport-8.15.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /home/codespace/.local/lib/python3.12/site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2.2.2)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.7.4)\n",
      "Downloading elasticsearch-8.15.0-py3-none-any.whl (523 kB)\n",
      "Downloading elastic_transport-8.15.0-py3-none-any.whl (64 kB)\n",
      "Installing collected packages: elastic-transport, elasticsearch\n",
      "Successfully installed elastic-transport-8.15.0 elasticsearch-8.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a1fff58-e693-4dc4-8266-94671aae8467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch(\n",
    "    'http://localhost:9200'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4051356f-07af-471c-a112-6b46554de48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '39971c2048d9', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'SSG_918tQ5idHjfGEIxuIQ', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4b6647f-3d29-48b0-b917-dc7756cd82a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course_questions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90dcc10-0800-42dd-95ab-47e124b37300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating index\n",
    "es_client.indices.create(index=index_name,body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c7dc5f8-741e-48b1-a647-cec93371c117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.66.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23cf6b7b-20c1-4ff0-bd27-d626a74ec797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c00d104-b4be-46b7-a22a-db39ebc2205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing documents\n",
    "for doc in documents:\n",
    "    es_client.index(index=index_name, document=doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7895874d-fd1b-4dd1-adc8-65b2264c2177",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How can I run Kafka?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e6c48eba-665f-4324-b293-a95f3e8a9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"data-engineering-zoomcamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "    search_result = es_client.search(index = index_name, body = search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    for doc in search_result['hits']['hits']:\n",
    "        result_docs.append(doc['_source'])\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3af30ac6-8745-46b4-8eef-34dc512543b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    results = elastic_search(query)\n",
    "    prompt = build_prompt(query, results)\n",
    "    response = llm_response(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1f268a7a-d8a3-4de4-8446-55d1b6999648",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dc54cd9f-0461-4227-8de8-d11f80423e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To run Kafka, you can follow the instructions provided for the specific task you want to achieve:\\n\\n1. **Running Java Kafka producer/consumer/kstreams/etc. in terminal:**\\n   - Navigate to your project directory and use the following command:\\n     ```shell\\n     java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n     ```\\n\\n2. **Running a Python Kafka producer:**\\n   - If you encounter the \"Module \\'kafka\\' not found\" error, you will need to create and use a virtual environment. Follow these steps:\\n     - Create a virtual environment and install the required packages by running the following commands:\\n       ```shell\\n       python -m venv env\\n       source env/bin/activate\\n       pip install -r ../requirements.txt\\n       ```\\n     - Activate the virtual environment each time you need to run the Python file:\\n       ```shell\\n       source env/bin/activate\\n       ```\\n     - To deactivate the virtual environment:\\n       ```shell\\n       deactivate\\n       ```\\n     - Note: On Windows, the activation command is slightly different (use `env/Scripts/activate`).\\n\\nMake sure that Docker images are up and running before you create the virtual environment if Docker is part of your setup.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d4dbd-25e5-4fad-8365-0a1db3e05f33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
